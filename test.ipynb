{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Libraries"
      ],
      "metadata": {
        "id": "IXupuu8TjJsn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBDffOplewUC"
      },
      "outputs": [],
      "source": [
        "# Install all the requirements\n",
        "!pip install -r https://raw.githubusercontent.com/FranckSoma/ChatGPT_Code_Improver/main/requirements.txt\n",
        "\n",
        "# Install PIL for image processing\n",
        "!pip install Pillow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividing Training and Evaluation Images\n"
      ],
      "metadata": {
        "id": "1vt5MMVeuIpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(source_folder, train_folder, eval_folder, eval_ratio):\n",
        "    \"\"\"Split data into training and evaluation sets.\"\"\"\n",
        "    if not os.path.exists(train_folder):\n",
        "        os.makedirs(train_folder)\n",
        "    if not os.path.exists(eval_folder):\n",
        "        os.makedirs(eval_folder)\n",
        "\n",
        "    images = [img for img in os.listdir(source_folder) if img.endswith('.png') or img.endswith('.jpg')]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    eval_size = int(len(images) * eval_ratio)\n",
        "\n",
        "    for img in images[:eval_size]:\n",
        "        shutil.move(os.path.join(source_folder, img), os.path.join(eval_folder, img))\n",
        "\n",
        "    for img in images[eval_size:]:\n",
        "        shutil.move(os.path.join(source_folder, img), os.path.join(train_folder, img))\n",
        "\n",
        "# Adjust these paths and values\n",
        "source_folder = 'FFHQ/Images'  # Path to your dataset\n",
        "train_folder = 'FFHQ/Train'    # Path to the training set folder\n",
        "eval_folder = 'FFHQ/Eval'      # Path to the evaluation set folder\n",
        "eval_ratio = 0.2               # Percentage of data to be used for evaluation\n",
        "\n",
        "\n",
        "split_data(source_folder, train_folder, eval_folder, eval_ratio)\n"
      ],
      "metadata": {
        "id": "lak40eNZuQKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model\n"
      ],
      "metadata": {
        "id": "3vUyBGKiv-x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m torch.distributed.launch --nproc_per_node=2 train_styleswin.py --batch 4 --path /FFHQ/Train --checkpoint_path /trained_model --sample_path /temp --size 256 --G_channel_multiplier 2 --bcr --D_lr 0.0002 --D_sn --ttur --eval_gt_path /FFHQ/Eval --lr_decay --lr_decay_start_steps 775000 --iter 1000000"
      ],
      "metadata": {
        "id": "FvO0OeyLwCQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PID Score and Demo Images"
      ],
      "metadata": {
        "id": "l2D0Xbb7wffO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m torch.distributed.launch --nproc_per_node=1 train_styleswin.py --sample_path /generated_images --size 256 --G_channel_multiplier 2 --ckpt /trained_model --eval --val_num_batches 12500 --val_batch_size 4 --eval_gt_path /FFHQ/Eval\n"
      ],
      "metadata": {
        "id": "Y2Y54w4twkmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}